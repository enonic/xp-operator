= Step-by-step Guide to Run XP on GKE
:toc: right
:imagesdir: images

This section contains a step-by-step guide on how to create a managed k8s cluster in GCP and install XP operator.

== Prerequisites

You need an account to create resources in GCP. Then create a GCP project in which the k8s cluster will run on. 
On your client machine install these programs:


Kubectl:: Is the Kubernetes command-line tool, kubectl, allows you to run commands against Kubernetes clusters. Download it https://kubernetes.io/docs/tasks/tools/install-kubectl/[here].

Gcloud CLI:: Command-line tool to manage resources in GCP. Download it https://cloud.google.com/sdk/docs/install[here]

== Create a GKE Cluster

1. Enable Kubernetes Engine API: if the kubernetes engine API is not enabled on your GCP project, you need to enable it. 
+
image::../images/gkeEnablek8sapi.png[Enable API]

2. After enabling Kubernetes Enging API, it will show you an option to create a k8s cluster. 
+
image::../images/gkeCreateClusterPage.png[Create GKE Cluster]
+
If you don't get this window, click on the hamburger menu and chose `Kubernetes Engine` -> `clusters` as shown in the image below.
+
image::../images/gkeGetClusterslist.png[GKE Clusters]

3. Click on `Create` button. This will take you to the k8s cluster creation wizard. By default it starts the creation process for `autopilot` k8s cluster. Click on the `Switch to standard cluster` button.  (Note: Current xp operator version works only on `standard` cluster type)

4. Follow the cluster creation steps by setting the values based on your cluster needs. Make sure to chose kubernetes version >= 1.27 which is requried by XP operator.

5. Once the k8s cluster is created, click on the name of the cluster and you will get a `Connect` button on the top middle section of the page. This shows you the gcloud command you can use to connect to the k8s cluster from your computer.

6. Copy and run the "gcloud" command. If the command outputs `kubeconfig entry generated for <newly-created-k8s-cluster-name>`, it means proper kubectl config is generated on your computer and you are successfully authenticated to the k8s cluster. 

7. To test your access to the k8s cluster run the command
[source,bash]
----
$ kubectl get namespaces
----

This should display the list of namespaces in the newly created k8s cluster. The "Age" column in the output shows how long has it been since the namespaces are created. 

[source,bash]
----
$ kubectl get storageclasses
----

This should display the list of storage classes provisioned by GKE cluster. 


== Deploy XP Operator in k8s

=== Create chart values file

The chart `values.yaml` file is how you generally configure a deployment with Helm (to learn more about how Helm uses values files, visit the https://helm.sh/docs/chart_template_guide/values_files/#helm[Helm developer docs]). You can read more about available values you can configure for the operator in the https://github.com/enonic/xp-operator/tree/master/helm[Helm chart readme]. Lets create a Helm values file to configure the operator:

NOTE: Here is an example values file; you may need to change the default storage class name to the one you get in your GKE cluster. The shared storage class name is required to run XP in cluster mode. Refer to the section <<Run XP in Cluster Mode>> for more information about the requirement. Depending on your choice of shared storage class name, you may need to update the values.yaml file. 
If you prefer to run XP only in single mode, comment out the shared storage class specification line. When you want to run XP in cluster mode, the operator can easily be updated by changing the values.yaml file and running `helm upgrade`.

.values.yaml
[[values]]
[source,yaml]
----
config: |-
  # Set storage class names for volumes to be used by XP deployments.
  # The default storage class can be any storage class from your k8s cluster.
  # The shared storage class is used to run XP in cluster mode and it has to support ReadWriteMany!
  operator.charts.values.storage.default.storageClassName=standard
  operator.charts.values.storage.shared.storageClassName=nfs

  # Default CPU and RAM requests
  operator.charts.values.resources.cpu.defaultRequests=1
  operator.charts.values.resources.memory.defaultRequests=4G
----


=== Installing chart

[source,bash]
----
$ helm upgrade --install \
	--namespace kube-system \
	--values values.yaml \
	xp-operator \
	https://repo.enonic.com/repository/helm/xp-operator-0.22.2.tgz

Release "xp-operator" does not exist. Installing it now.
NAME: xp-operator
LAST DEPLOYED: Wed Jan  3 00:11:57 2024
NAMESPACE: kube-system
STATUS: deployed
REVISION: 1
TEST SUITE: None
----

=== Verify installation

First find out the name of the operator pod:

[source,bash]
----
$ kubectl -n kube-system get pods

NAME                                                                READY   STATUS              RESTARTS   AGE
pod/event-exporter-gke-7bf6c99dcb-7dl56                             2/2     Running             0          16d
pod/kube-dns-5bfd847c64-2562d                                       4/4     Running             0          16d
pod/kube-proxy-gke-xp-test-gke-cluster-default-pool-d0fdd01c-jnfl   1/1     Running             0          16d
pod/l7-default-backend-d86c96845-j6m9b                              1/1     Running             0          16d
pod/xp-operator-684bb48cc5-bqjqc                                    0/1     ContainerCreating   0          9s
----

Then look at the operator logs to see if there are any errors:

[source,bash]
----
$ kubectl -n kube-system logs -f xp-operator-684bb48cc5-bqjqc 

exec java -Doperator.charts.path=helm -Djava.util.logging.manager=org.jboss.logmanager.LogManager -javaagent:/opt/agent-bond/agent-bond.jar=jmx_exporter{{9779:/opt/agent-bond/jmx_exporter_config.yml}} -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/quarkus-run.jar
__  ____  __  _____   ___  __ ____  ______
 --/ __ \/ / / / _ | / _ \/ //_/ / / / __/
 -/ /_/ / /_/ / __ |/ , _/ ,< / /_/ /\ \
--\___\_\____/_/ |_/_/|_/_/|_|\____/___/
2024-01-02 23:12:24,760 INFO  io.quarkus - java-operator 0.22.1 on JVM (powered by Quarkus 2.16.6.Final) started in 6.579s. Listening on: https://0.0.0.0:8443
2024-01-02 23:12:24,762 INFO  io.quarkus - Profile prod activated.
2024-01-02 23:12:24,764 INFO  io.quarkus - Installed features: [cdi, micrometer, rest-client, resteasy, resteasy-jackson, smallrye-context-propagation, vertx]
2024-01-02 23:12:25,808 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorIngress'
2024-01-02 23:12:25,889 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXpClientCacheInvalidate'
2024-01-02 23:12:27,738 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXp7DeploymentHelm'
2024-01-02 23:12:27,787 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXp7AppStatusOnDeployments'
2024-01-02 23:12:27,799 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorDeleteAnnotation'
2024-01-02 23:12:27,803 INFO  com.eno.kub.ope.Operator - Adding schedule 'OperatorInformers' [delay: 16337, period: 30000]
2024-01-02 23:12:27,803 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXp7ConfigStatus'
2024-01-02 23:12:27,804 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorIngressLabel'
2024-01-02 23:12:27,804 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXp7AppInstaller'
2024-01-02 23:12:27,805 INFO  com.eno.kub.ope.Operator - Adding schedule 'OperatorXp7AppInstaller' [delay: 15212, period: 60000]
2024-01-02 23:12:27,805 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXp7AppInstallerOnDeployments'
2024-01-02 23:12:27,806 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorConfigMapEvent'
2024-01-02 23:12:27,803 INFO  com.eno.kub.ope.Operator - Adding schedule 'OperatorConfigMapSync' [delay: 13252, period: 60000]
2024-01-02 23:12:27,804 INFO  com.eno.kub.ope.Operator - Adding schedule 'OperatorIngressLabel' [delay: 6622, period: 60000]
2024-01-02 23:12:27,806 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXp7Config'
2024-01-02 23:12:27,807 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorIngressCertSync'
2024-01-02 23:12:27,807 INFO  com.eno.kub.ope.Operator - Adding schedule 'OperatorXp7ConfigSync' [delay: 10124, period: 60000]
2024-01-02 23:12:27,808 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorDomainCertSync'
2024-01-02 23:12:27,809 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXp7AppStartStopper'
2024-01-02 23:12:27,809 INFO  com.eno.kub.ope.Operator - Adding schedule 'OperatorXp7AppStartStopper' [delay: 14806, period: 60000]
2024-01-02 23:12:27,809 INFO  com.eno.kub.ope.Operator - Adding listener 'OperatorXp7DeploymentStatus'
2024-01-02 23:12:27,810 INFO  com.eno.kub.ope.Operator - Adding schedule 'OperatorXp7DeploymentStatus' [delay: 4146, period: 60000]
2024-01-02 23:12:27,810 INFO  com.eno.kub.ope.Operator - Adding schedule 'OperatorXp7AppStatus' [delay: 19524, period: 60000]
2024-01-02 23:12:32,807 INFO  com.eno.kub.ope.Operator - Starting informers
----


== Run XP in Single Mode
When running XP in single mode, there will be a single pod running XP.

=== XP deployment for single Mode

You can get example deployment file to deploy XP in Single mode from
link:/https://github.com/enonic/xp-operator/kubernetes[Example Codes]. Copy single-xp7deployment-with-other-resources.yaml deployment file
and make changes to it as per your requirement. For instance parameters like namespace to which XP is going to be deployed, RAM and CPU size. Once you finished editting the file, run the command below.


[source,bash]
----
$ kubectl apply -f single-xp7deployment-with-other-resources.yaml

namespace/my-namespace created
xp7deployment.enonic.cloud/my-deployment created
xp7app.enonic.cloud/contentstudio created
xp7config.enonic.cloud/my-config created
ingress.networking.k8s.io/my-domain-com created
----

=== Access XP Admin page
Once the XP pods have started you can open up admin page through the ingress controller, if you have one set up or using port-forwarding. To login using the 'su' user you need to first fetch the su password from the secret resource as shown below.

==== Fetching SU password

[source,bash]
----
$ kubectl -n my-namespace get secret su -o go-template="{{ .data.pass | base64decode }}"

NGDDlGdFX6#3Rw
----

==== Access admin (bypassing ingress)
In this method, XP admin is accessible directly on the pod over port 8080 bypassing ingress:

[source,bash]
----
$ kubectl -n my-namespace port-forward main-0 8080

Forwarding from 127.0.0.1:8080 -> 8080
Forwarding from [::1]:8080 -> 8080
----

Then open up http://localhost:8080[localhost:8080] in your browser.

==== Access admin (through ingress)

If you have setup ingress controller, you can access xp-admin through the admin end point you configured.


== Run XP in Cluster Mode

To run xp in cluster mode it is required to have an NFS based shared volume that can be mounted as Read-Write by multiple nodes at a time. The standard storage class in `GKE` does not support `ReadWriteMany` mode. Most storage classes that support `ReadWriteMany` access mode have also a restriction in changing the modified time of files that XP requires. 

In GKE, Filestore CSI driver based storage class with RWM* mode can be used to deploy XP in cluster mode. However it is an expensive option due to :
1. Very high minimum allowed size 
2. higher cost per GB

Another alternative is to mount a disk from an existing external NFS server or use a provisoner to create NFS server in your GKE cluster and create an NFS based storage class from it. See our <<nfs#,NFS storage class>> guide for more information.

Note: If you have already deployed XP operator with NFS based shared storage class, you can continue to the next step. If not update the values.yaml file from above and follow the steps in section [Deploy XP Operator in k8s]. After deploying the XP operator with shared storage support, you can continue to the next steps.

=== XP deployment for cluster Mode

You can get example deployment file to deploy XP in cluster mode from
link:/https://github.com/enonic/xp-operator/kubernetes[Example Codes]. Copy cluster-xp7deployment-with-other-resources.yaml deployment file
and make changes to it as per your requirement. For instance parameters like namespace in which XP is going to be deployed, RAM and CPU size, types and number of cluster nodes can be changed in the deployment file. Once you finished editting the file, run the command below.


[source,bash]
----
$ kubectl apply -f cluster-xp7deployment-with-other-resources.yaml

namespace/my-namespace created
xp7deployment.enonic.cloud/my-deployment created
xp7app.enonic.cloud/contentstudio created
xp7config.enonic.cloud/my-config created
ingress.networking.k8s.io/my-domain-com created
----

=== Access XP Admin page
Once the XP pods have started you can open up admin page through the ingress controller, if you have one set up or using port-forwarding. First fetch the 'su' password from the secret resource as shown below.

==== Fetching SU password

[source,bash]
----
$ kubectl -n my-namespace get secret su -o go-template="{{ .data.pass | base64decode }}"

NGDDlGdFX6#3Rw
----

==== Access admin (bypassing ingress)
In this method, XP admin is accessible directly on the pod over port 8080 bypassing ingress:

[source,bash]
----
$ kubectl -n my-namespace port-forward master-0 8080

Forwarding from 127.0.0.1:8080 -> 8080
Forwarding from [::1]:8080 -> 8080
----

Then open up http://localhost:8080[localhost:8080] in your browser.

Note: In a cluster mode there will be more than one pod and login with port-forwarding can be done through any of those pods. In the example, we used master-0, but any of the other pods can also be used.

==== Access admin (through ingress)

If you have setup ingress controller, you can access xp-admin through the admin end point you configured.

== Teardown

Once you are done with your cluster, you can delete the k8s cluster from the GCP console or using gcloud cli:

[source,bash]
----
$ gcloud container clusters delete <CLUSTER_NAME>

----
