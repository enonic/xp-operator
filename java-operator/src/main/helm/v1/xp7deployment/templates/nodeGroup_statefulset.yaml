# Create StatefulSet for each nodeGroup
{{- range $nodeGroup := .Values.deployment.spec.nodeGroups }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ $nodeGroup.name }}
  namespace: {{ $.Values.deployment.namespace }}
  annotations:
    {{ $.Values.annotationKeys.applyPriority }}: "90"
  labels:
    {{ $.Values.labelKeys.managed }}: true
    {{ $.Values.labelKeys.nodeGroup }}: {{ $nodeGroup.name }}
    {{- with $.Values.defaultLabels }}
    {{- toYaml . | nindent 4 }}
    {{- end }}
  ownerReferences:
    {{- with $.Values.ownerReferences }}
    {{- toYaml . | nindent 4 }}
    {{- end }}
spec:
  serviceName: {{ $.Values.discoveryService }}
  replicas: {{ if $.Values.deployment.spec.enabled }}{{ $nodeGroup.replicas }}{{ else }}0{{end}}
  revisionHistoryLimit: 10
  podManagementPolicy: Parallel
  updateStrategy:
    type: {{ $.Values.pods.updateStrategy }}
  selector:
    matchLabels:
      {{ $.Values.labelKeys.managed }}: true
      {{ $.Values.labelKeys.nodeGroup }}: {{ $nodeGroup.name }}
      {{ $.Values.labelKeys.deployment }}: {{ $.Values.deployment.name }}
      {{- with $.Values.defaultLabels }}
      {{- toYaml . | nindent 6 }}
      {{- end }}
  template:
    metadata:
      annotations:
        enonic.cloud/metrics.xp7: "true"
        enonic.cloud/logs.xp7: "true"
        {{- if $.Values.backup.enabled }}
        backup.velero.io/backup-volumes: "{{- join "," $.Values.volumes.backups }}"
        pre.hook.backup.velero.io/container: "exp"
        pre.hook.backup.velero.io/command: '["/usr/local/bin/backup.sh"]'
        {{- end }}
        {{- if index $.Values "settings.linkerd" }}
        linkerd.io/inject: enabled
        {{- end }}
      labels:
        {{ $.Values.labelKeys.managed }}: true
        {{ $.Values.labelKeys.nodeGroup }}: {{ $nodeGroup.name }}
        {{ $.Values.labelKeys.master }}: {{ $nodeGroup.master }}
        {{ $.Values.labelKeys.data }}: {{ $nodeGroup.data }}
        {{ $.Values.labelKeys.deployment }}: {{ $.Values.deployment.name }}
        {{- with $.Values.defaultLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      serviceAccount: xp-node-sa
      serviceAccountName: xp-node-sa
      {{- if $.Values.pods.nodeGroupAntiAffinity }}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: {{ $.Values.labelKeys.nodeGroup }}
                    operator: In
                    values:
                      - {{ $nodeGroup.name }}
              topologyKey: "kubernetes.io/hostname"
      {{- end }}
      restartPolicy: Always
      dnsPolicy: ClusterFirst
      schedulerName: default-scheduler
      terminationGracePeriodSeconds: {{ $.Values.pods.terminationGracePeriodSeconds }}

      securityContext:
        fsGroup: {{ $.Values.pods.securityContext.fsGroup }}

      {{- if $.Values.pods.sysctlInitContainer }}
      initContainers:
        - name: configure-sysctl
          securityContext:
            runAsUser: 0
            privileged: true
          image: busybox
          imagePullPolicy: {{ $.Values.image.pullPolicy }}
          command: ["sysctl", "-w", "vm.max_map_count=262144"]
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
      {{- end }}

      containers:
        - name: exp
          image: {{ $.Values.image.nameTemplate | replace "%s" $.Values.deployment.spec.xpVersion }}
          imagePullPolicy: {{ $.Values.image.pullPolicy }}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File

          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: {{ $.Values.pods.securityContext.user }}

          resources:
            requests:
              cpu: {{ if $.Values.resources.cpu.defaultRequests }}{{ $.Values.resources.cpu.defaultRequests }}{{ else }}{{ $nodeGroup.resources.cpu }}{{ end }}
              memory: {{ if $.Values.resources.memory.defaultRequests }}{{ $.Values.resources.memory.defaultRequests }}{{ else }}{{ $nodeGroup.resources.memory }}{{ end }}
            limits:
              cpu: {{ $nodeGroup.resources.cpu }}
              memory: {{ $nodeGroup.resources.memory }}

          ports:
            - name: xp-stats
              containerPort: 2609
              protocol: TCP
            - name: xp-main
              containerPort: 8080
              protocol: TCP
            - name: es-http
              containerPort: 9200
              protocol: TCP
            - name: es-transport
              containerPort: 9300
              protocol: TCP

          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: XP_NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: XP_NODE_GROUP
              value: {{ $nodeGroup.name }}
            - name: XP_CLUSTERED # This is to ensure that XP is restarted when deployment is changed from clustered to non clustered
              value: {{ if $.Values.deployment.clustered }}true{{ else }}false{{ end }}
            - name: XP_HZ_MIN_SIZE
              value: {{ $.Values.deployment.clusterMajority }}
            - name: XP_ES_MIN_MASTERS
              value: {{ $.Values.deployment.minimumMasterNodes }}
            - name: XP_ES_MIN_DATAS
              value: {{ $.Values.deployment.minimumDataNodes }}
            - name: XP_IS_MASTER
              value: {{ if $nodeGroup.master }}true{{ else }}false{{ end }}
            - name: XP_IS_DATA
              value: {{ if $nodeGroup.data }}true{{ else }}false{{ end }}
            - name: XP_NODE_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: SU_PASS_HASH
              valueFrom:
                secretKeyRef:
                  name: su
                  key: passHash
                  optional: false
            - name: PRE_APP_HASH
              value: {{ $.Values.deployment.preInstalledAppHash }}
          {{- range $env := $nodeGroup.env }}
            - name: {{ $env.name }}
              value: {{ $env.value }}
          {{- end }}


          {{- if semverCompare ">= 7.13.0" $.Values.deployment.spec.xpVersion }}
          startupProbe:
            httpGet:
              path: "/healthz"
              port: 2609
              scheme: HTTP
            failureThreshold: 20
            initialDelaySeconds: 30
            periodSeconds: 5
            timeoutSeconds: 2
          livenessProbe:
            httpGet:
              path: "/healthz"
              port: 2609
              scheme: HTTP
            failureThreshold: 10
            timeoutSeconds: 2
          readinessProbe:
            httpGet:
              path: "/ready"
              port: 2609
              scheme: HTTP
            failureThreshold: 2
            timeoutSeconds: 2
          {{- end }}

          {{- if $.Values.deployment.clustered }}
          lifecycle:
            preStop:
              exec:
                command: ["/bin/bash","{{ $.Values.dirs.extraConfig }}/preStop.sh"]
          {{- end }}

          volumeMounts:
            - name: config
              mountPath: {{ $.Values.dirs.config }}
            - name: extra-config
              mountPath: {{ $.Values.dirs.extraConfig }}
            - name: extra-config
              mountPath: {{ $.Values.files.setEnv }}
              subPath: preStart.sh
        {{- range $disk := $nodeGroup.resources.disks }}
        {{- include "volumeMount" (dict "disk" $disk "Values" $.Values) | indent 12 }}
        {{- end }}
        {{- range $disk := $.Values.deployment.spec.nodesSharedDisks }}
        {{- include "volumeMount" (dict "disk" $disk "Values" $.Values) | indent 12 }}
        {{- end }}
        - name: events
          image: {{ $.Values.image.nameTemplate | replace "%s" $.Values.deployment.spec.xpVersion }}
          imagePullPolicy: {{ $.Values.image.pullPolicy }}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File

          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: {{ $.Values.pods.securityContext.user }}

          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: POD_UID
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.uid
            - name: XP_NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: XP_NODE_GROUP
              value: {{ $nodeGroup.name }}
            - name: K8S_TOKEN
              valueFrom:
                secretKeyRef:
                  name: xp-events-sa-secret
                  key: token

          volumeMounts:
            - name: config
              mountPath: {{ $.Values.dirs.config }}
            - name: extra-config
              mountPath: {{ $.Values.dirs.extraConfig }}

          command: ["bash"]
          args: ["extra-config/events.sh"]

        {{ if and (not $.Values.deployment.clustered) $.Values.backup.enabled }}
        - name: backup
          image: {{ $.Values.backup.agent.image }}
          imagePullPolicy: {{ $.Values.image.pullPolicy }}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File

          securityContext:
            capabilities:
              drop:
                - ALL
            runAsNonRoot: true
            runAsUser: {{ $.Values.pods.securityContext.user }}

          resources:
            limits:
              cpu: {{ $.Values.backup.agent.limits.cpu }}
              memory: {{ $.Values.backup.agent.limits.memory }}

          ports:
            - name: backup
              containerPort: 8000
              protocol: TCP

          env:
            # Basic k8s configuration
            - name: AGENT_MODE
              value: k8s
            - name: AGENT_K8S_TOKEN
              valueFrom:
                secretKeyRef:
                  name: xp-backup-sa-secret
                  key: token
            - name: AGENT_K8S_NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: AGENT_K8S_POD
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: AGENT_K8S_CONTAINER
              value: backup
            - name: RESTIC_CACHE_DIR
              value: /restic/cache
            # Annotation configuration
            - name: AGENT_K8S_ANNOTATIONS_VOLUME
              value: backup.velero.io/backup-volumes
            - name: AGENT_K8S_ANNOTATIONS_PRESCRIPT
              value: pre.hook.backup.velero.io/command
            - name: AGENT_K8S_ANNOTATIONS_PRESCRIPTCONTAINER
              value: pre.hook.backup.velero.io/container
            - name: AGENT_K8S_ANNOTATIONS_POSTSCRIPT
              value: post.hook.backup.velero.io/command
            - name: AGENT_K8S_ANNOTATIONS_POSTSCRIPTCONTAINER
              value: post.hook.backup.velero.io/container
            # Any extra config
            {{- range $k, $v := $.Values.backup.agent.env }}
            - name: {{ $k }}
              value: {{ $v }}
            {{- end }}


          volumeMounts:
            - name: backup-config
              mountPath: /etc/ec/backup-agent
            - name: restic
              mountPath: /restic
          {{- range $disk := $nodeGroup.resources.disks }}
            {{- include "volumeMount" (dict "disk" $disk "Values" $.Values) | indent 12 }}
          {{- end }}
          {{- range $disk := $.Values.deployment.spec.nodesSharedDisks }}
            {{- include "volumeMount" (dict "disk" $disk "Values" $.Values) | indent 12 }}
          {{- end }}
        {{- end }}

      volumes:
        - name: config
          configMap:
            defaultMode: "420"
            name: {{ $nodeGroup.name }}
        - name: extra-config
          configMap:
            defaultMode: "420"
            name: extra-config
        - name: backup-config
          configMap:
            defaultMode: "420"
            name: backup-config
        {{- range $volume := $.Values.deployment.spec.nodesSharedVolumes }}
        - name: {{ $volume.name }}
          persistentVolumeClaim:
            claimName: {{ $volume.name }}
        {{- end }}
        {{- range $disk := $.Values.deployment.spec.nodesSharedDisks }}
        {{- if not $disk.volume }}
        - name: {{ $disk.name }}
          persistentVolumeClaim:
            claimName: {{ $disk.name }}
        {{- end }}
        {{- end }}
  volumeClaimTemplates:
    {{- range $volume := $nodeGroup.resources.volumes }}
    {{ include "volumeClaimTemplate" (dict "volume" $volume "nodeGroup" $nodeGroup "Values" $.Values) | indent 4 }}
    {{- end }}
    {{- range $volume := $nodeGroup.resources.disks }}
    {{- if not $volume.volume }}
    {{ include "volumeClaimTemplate" (dict "volume" $volume "nodeGroup" $nodeGroup "Values" $.Values) | indent 4 }}
    {{- end }}
    {{- end }}
    {{ if and (not $.Values.deployment.clustered) $.Values.backup.enabled }}
    - metadata:
        name: restic
      spec:
        volumeMode: Filesystem
        storageClassName: {{ $.Values.storage.default.storageClassName }}
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: {{ $.Values.backup.cacheSize }}
    {{- end }}
---
{{- end }}

{{- define "volumeMount" -}}
{{- if .disk.volume }}
- name: {{ .disk.volume }}
  mountPath: {{ index .Values.volumes.mounts .disk.name }}
  subPath: {{ .disk.name }}
{{- else }}
- name: {{ .disk.name }}
  mountPath: {{ index .Values.volumes.mounts .disk.name }}
{{- end }}
{{- end }}

{{ define "volumeClaimTemplate" }}
- metadata:
    name: {{ .volume.name }}
    annotations:
      {{- with .Values.storage.default.annotations }}
      {{- toYaml . | nindent 6 }}
      {{- end }}
    labels:
      {{- if and .Values.backup.enabled (not (has .volume.name .Values.volumes.backups)) }}
      velero.io/exclude-from-backup: true
      {{- end }}
      {{ .Values.labelKeys.managed }}: true
      {{ .Values.labelKeys.nodeGroup }}: {{ .nodeGroup.name }}
      {{- with .Values.defaultLabels }}
      {{- toYaml . | nindent 6 }}
      {{- end }}
  spec:
    volumeMode: Filesystem
    storageClassName: {{ .volume.class | default .Values.storage.default.storageClassName }}
    accessModes:
      - ReadWriteOnce
    resources:
      requests:
        storage: {{ .volume.size }}
{{- end }}
